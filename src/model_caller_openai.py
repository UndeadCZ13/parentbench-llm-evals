# src/model_caller_openai.py
"""ç»Ÿä¸€çš„æ¨¡å‹è°ƒç”¨å°è£…:
- backend="openai": ä½¿ç”¨ OpenAI ChatCompletions
- backend="ollama"/"local": ä½¿ç”¨æœ¬åœ°æˆ– Cloud Ollama (chat æ¥å£)
"""

from __future__ import annotations

import os
import time
import random
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
import requests

load_dotenv()


# ========= å…¬å…±è¾…åŠ© =========

def _build_messages(prompt: str, system_prompt: Optional[str] = None) -> List[Dict[str, str]]:
    messages: List[Dict[str, str]] = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})
    return messages


# ========= OpenAI è°ƒç”¨ =========

def call_openai_chat(
    prompt: str,
    model: str,
    system_prompt: Optional[str] = None,
    temperature: float = 0.2,
    max_tokens: int = 1024,
    max_retries: int = 3,
    **_: Any,
) -> Optional[str]:
    """è°ƒç”¨ OpenAI / å…¼å®¹ OpenAI çš„ ChatCompletions æ¥å£ã€‚"""
    from openai import OpenAI

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("[ERROR] OPENAI_API_KEY æœªè®¾ç½®ï¼Œæ— æ³•è°ƒç”¨ OpenAI æ¨¡å‹ã€‚")
        return None

    base_url = os.getenv("OPENAI_BASE_URL")  # å¯é€‰
    client = OpenAI(api_key=api_key, base_url=base_url or None)

    messages = _build_messages(prompt, system_prompt)

    for attempt in range(1, max_retries + 1):
        try:
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
            )
            return resp.choices[0].message.content or ""
        except Exception as e:
            print(f"[WARN] è°ƒç”¨ OpenAI æ¨¡å‹å¤±è´¥ï¼Œç¬¬ {attempt}/{max_retries} æ¬¡å°è¯•: {e}")
            if attempt >= max_retries:
                print("[ERROR] OpenAI å¤šæ¬¡é‡è¯•ä»å¤±è´¥ï¼Œæœ¬æ¡è®°å½•è¿”å› Noneã€‚")
                return None
            # ç®€å•é€€é¿
            sleep_sec = 1.0 * attempt + random.random() * 0.5
            time.sleep(sleep_sec)

    return None


# ========= Ollama è°ƒç”¨ =========

def _ollama_request(
    url: str,
    payload: Dict[str, Any],
    desc: str,
    headers: Optional[Dict[str, str]] = None,
) -> Optional[Dict[str, Any]]:
    """å‘é€è¯·æ±‚; å¦‚æœ status!=200, è¿”å›ä¸€ä¸ªå¸¦ _error çš„ dict, è®©ä¸Šå±‚å¯ä»¥åŒºåˆ† 429 ç­‰æƒ…å†µã€‚"""
    try:
        resp = requests.post(url, json=payload, timeout=600, headers=headers)
    except Exception as e:
        print(f"[ERROR] è°ƒç”¨ Ollama {desc} æ¥å£å¤±è´¥: {e}")
        return {"_error": True, "status_code": None, "raw_body": str(e)}

    if resp.status_code != 200:
        body = resp.text[:500]
        print(f"[ERROR] Ollama {desc} æ¥å£è¿”å›é 200: {resp.status_code}, body={body}")
        return {"_error": True, "status_code": resp.status_code, "raw_body": body}

    try:
        data = resp.json()
    except Exception as e:
        print(f"[ERROR] è§£æ Ollama {desc} JSON å¤±è´¥: {e}, body={resp.text[:500]}")
        return {"_error": True, "status_code": resp.status_code, "raw_body": resp.text[:500]}

    return data


def call_ollama_chat(
    prompt: str,
    model: str = "qwen3:8b",
    system_prompt: Optional[str] = None,
    temperature: float = 0.1,
    max_tokens: int = 1024,
    timeout: int = 600,          # ç›®å‰ä¸»è¦ç”¨äºæ–‡æ¡£è¯´æ˜ï¼Œrequests å†…éƒ¨ timeout å›ºå®šä¸º 600s
    max_retries: int = 10,        # ğŸ” é‡è¯•æ¬¡æ•°
    base_delay: float = 1,     # ğŸ˜´ Cloud è°ƒç”¨åŸºç¡€ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    **_: Any,
) -> Optional[str]:
    """è°ƒç”¨ Ollama /api/chatã€‚
    - å¯¹æœ¬åœ°æ¨¡å‹å’Œ Cloud æ¨¡å‹éƒ½é€‚ç”¨
    - åŠ å…¥ï¼š
        - Cloud è°ƒç”¨å‰çš„éšæœº sleepï¼Œé¿å…ç¬æ—¶ QPS è¿‡é«˜å¯¼è‡´é™æµ
        - å¤±è´¥æ—¶çš„é‡è¯•ï¼ˆæœ€å¤š max_retries æ¬¡ï¼‰ï¼Œå¸¦ç®€å•é€€é¿
        - å¯¹ Cloud 429 usage limit çš„ä¸“é—¨å‹å¥½æç¤º

    ä½¿ç”¨æ–¹å¼ï¼š
    - æœ¬åœ° Ollamaï¼ˆé»˜è®¤ï¼‰:
        export OLLAMA_BASE_URL="http://localhost:11434"
    - Ollama Cloud:
        export OLLAMA_BASE_URL="https://ollama.com"
        export OLLAMA_API_KEY="ä½ çš„ Cloud API Key"
    """
    base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434").rstrip("/")
    api_url = f"{base_url}/api/chat"

    # æ„é€  Cloud / æœ¬åœ°å…±ç”¨çš„ messages
    messages = _build_messages(prompt, system_prompt)

    payload: Dict[str, Any] = {
        "model": model,
        "messages": messages,
        "stream": False,
        "options": {
            "temperature": temperature,
            "num_predict": max_tokens,
        },
    }

    # === è¯†åˆ«æ˜¯å¦ Cloudï¼Œå¹¶å‡†å¤‡ Authorization header ===
    headers: Dict[str, str] = {}
    is_cloud = base_url.startswith("https://") and "ollama.com" in base_url

    if is_cloud:
        api_key = os.environ.get("OLLAMA_API_KEY")
        if not api_key:
            print("[ERROR] æ£€æµ‹åˆ°æ­£åœ¨è°ƒç”¨ Ollama Cloud (OLLAMA_BASE_URL=https://ollama.com)ï¼Œ"
                  "ä½†æœªè®¾ç½®ç¯å¢ƒå˜é‡ OLLAMA_API_KEYã€‚Cloud è¯·æ±‚ä¼šå¤±è´¥ã€‚")
        else:
            # ç¡®ä¿ key ä¸å«å¥‡æ€ªå­—ç¬¦ï¼Œé¿å… 'latin-1' ç¼–ç é”™è¯¯
            try:
                api_key.encode("latin-1")
            except UnicodeEncodeError:
                print("[ERROR] OLLAMA_API_KEY ä¸­åŒ…å«é latin-1 å­—ç¬¦ï¼ˆå¯èƒ½æ˜¯å…¨è§’å¼•å·ã€çœç•¥å· â€¦ æˆ–å…¶å®ƒç‰¹æ®Šå­—ç¬¦ï¼‰ã€‚")
                print("       è¯·åœ¨ .env æˆ–ç¯å¢ƒå˜é‡é‡Œé‡æ–°çº¯æ–‡æœ¬ç²˜è´´ Ollama Cloud çš„åŸå§‹ API keyã€‚")
                return None

            headers["Authorization"] = f"Bearer {api_key}"

    last_error_msg: Optional[str] = None

    for attempt in range(1, max_retries + 1):
        # --- Cloud: æ¯æ¬¡è¯·æ±‚å‰ sleep ä¸€å°ä¼šï¼Œå‡å°‘é™æµ & æŠ–ä¸€ä¸‹ ---
        if is_cloud:
            # ç¬¬ä¸€æ¬¡ä¹Ÿç¨å¾®ç­‰ä¸€ä¸‹ï¼Œåç»­é‡è¯•ç­‰å¾—æ›´ä¹…ä¸€ç‚¹
            jitter = random.uniform(0.1, 0.3)
            delay = base_delay * (attempt - 1) + jitter
            if delay > 0:
                if attempt == 1:
                    print(f"[INFO] è°ƒç”¨ Ollama Cloudï¼Œsleep {delay:.2f}s ä»¥é¿å…ç¬æ—¶é™æµã€‚")
                else:
                    print(f"[INFO] Ollama Cloud é‡è¯•ç¬¬ {attempt} æ¬¡ï¼Œsleep {delay:.2f}s é€€é¿ã€‚")
                time.sleep(delay)

        # --- å‘é€è¯·æ±‚ ---
        data = _ollama_request(api_url, payload, "/api/chat", headers=headers or None)
        if not data:
            last_error_msg = "[ERROR] _ollama_request è¿”å›ç©ºæ•°æ®ã€‚"
        elif data.get("_error"):
            status = data.get("status_code")
            raw_body = data.get("raw_body") or ""
            body_lower = raw_body.lower()

            # ğŸŒŸ å…³é”®ï¼šä¸“é—¨å¤„ç† 429 usage limitï¼Œç”¨å‹å¥½è¯´æ˜æ›¿ä»£ç©ºå­—ç¬¦ä¸²ï¼Œå¹¶ä¸å†é‡è¯•
            if status == 429 and "usage limit" in body_lower:
                msg = (
                    "[Ollama Cloud 429] å·²è¾¾åˆ°å½“å‰æ¨¡å‹çš„ç”¨é‡ä¸Šé™ï¼Œ"
                    "è¯·ç­‰å¾…é¢åº¦é‡ç½®æˆ–å‡çº§å¥—é¤ã€‚"
                    "å¯ä»¥æ”¹ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚ qwen3:8b / deepseek-r1:latestï¼‰"
                    f" æˆ–å‡å°‘è¯„æµ‹æ¡æ•°ã€‚åŸå§‹è¿”å›: {raw_body}"
                )
                print(msg)
                return msg

            # å…¶ä»–é”™è¯¯ï¼Œè®°å½•åå‡†å¤‡é‡è¯•
            last_error_msg = f"[ERROR] Ollama /api/chat é”™è¯¯: status={status}, body={raw_body[:200]}"
        else:
            # æ­£å¸¸è¿”å›ï¼Œå°è¯•æå– content
            try:
                message = data.get("message") or {}
                content = message.get("content") or ""
                if content.strip():
                    return content
                else:
                    last_error_msg = "[WARN] Ollama /api/chat è¿”å›ç©ºå†…å®¹ã€‚"
            except Exception as e:
                last_error_msg = f"[ERROR] ä» Ollama /api/chat è¿”å›ä¸­æå– content å¤±è´¥: {e}, data={data}"

        # --- èµ°åˆ°è¿™é‡Œè¯´æ˜æœ¬æ¬¡è°ƒç”¨å¤±è´¥ï¼Œçœ‹çœ‹è¦ä¸è¦é‡è¯• ---
        if attempt < max_retries:
            # ä¸‹ä¸€è½®å¾ªç¯ä¼šè‡ªåŠ¨æ ¹æ® attempt å† sleep ä¸€æ¬¡
            print(f"[WARN] Ollama è°ƒç”¨å¤±è´¥ï¼Œå°†è¿›è¡Œç¬¬ {attempt + 1}/{max_retries} æ¬¡é‡è¯•ã€‚")
            continue
        else:
            break

    # å¤šæ¬¡é‡è¯•ä»å¤±è´¥
    print(f"[ERROR] Ollama è°ƒç”¨åœ¨é‡è¯• {max_retries} æ¬¡åä»å¤±è´¥ã€‚æœ€åé”™è¯¯ä¿¡æ¯ï¼š{last_error_msg}")
    return None


# ========= ç»Ÿä¸€å…¥å£ =========

def call_model(
    prompt: str,
    backend: str = "openai",
    model: Optional[str] = None,
    **kwargs: Any,
) -> Optional[str]:
    """ç»Ÿä¸€å…¥å£:
    - backend="openai": èµ° call_openai_chat
    - backend="ollama"/"local": èµ° call_ollama_chat
    """
    backend = backend.lower()

    if model is None:
        if backend == "openai":
            model = "gpt-4o-mini"
        elif backend in {"ollama", "local"}:
            model = "qwen3:8b"
        else:
            raise ValueError(
                f"backend='{backend}' éœ€è¦æŒ‡å®š model å‚æ•°ï¼Œæˆ–æ‰©å±• call_model ä¸­çš„é»˜è®¤é…ç½®ã€‚"
            )

    if backend == "openai":
        return call_openai_chat(prompt, model=model, **kwargs)
    elif backend in {"ollama", "local"}:
        return call_ollama_chat(prompt, model=model, **kwargs)
    else:
        raise ValueError(f"Unknown backend: {backend}. æ”¯æŒ 'openai', 'ollama', 'local'ã€‚")
